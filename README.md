# Reconhecimento de Emo√ß√µes em √Åudio

Este √© um projeto de **classifica√ß√£o de emo√ß√µes em √°udio**, onde √© utilizado o dataset **RAVDESS** para treinar um modelo capaz de identificar a emo√ß√£o presente em arquivos de √°udio enviados pelos usu√°rios. A aplica√ß√£o conta com uma interface interativa desenvolvida em **Streamlit**, permitindo que os usu√°rios enviem √°udios para an√°lise.

### üé• V√≠deo Explicativo: [Mini Projeto 2 - Trilha](https://www.youtube.com/watch?v=xf8GMCGjloQ&ab_channel=LuigiSchmitt)

![Descri√ß√£o da Imagem](https://i.imgur.com/33MqEWQ.png)

## Pipeline do Projeto

### 1. Coleta e Organiza√ß√£o dos Dados

- **Dataset Utilizado**: [RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)](https://zenodo.org/record/1188976)
  - O dataset cont√©m grava√ß√µes de √°udios com diferentes emo√ß√µes atuadas, como: alegria, tristeza, raiva, calma, medo, nojo, surpresa e neutro.
  - As emo√ß√µes s√£o representadas por n√∫meros nos nomes dos arquivos.

- **Organiza√ß√£o**:
  - Modality (01 = full-AV, 02 = video-only, 03 = audio-only).
  - Vocal channel (01 = speech, 02 = song).
  - Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).
  - Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.
  - Statement (01 = "Kids are talking by the door", 02 = "Dogs are sitting by the door").
  - Repetition (01 = 1st repetition, 02 = 2nd repetition).
  - Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).

### 2. Extra√ß√£o de Features

A extra√ß√£o de features √© uma etapa fundamental para converter os arquivos de √°udio em representa√ß√µes num√©ricas compreens√≠veis pelo modelo de machine learning. Foram utilizadas as seguintes t√©cnicas:

- **MFCCs (Mel-Frequency Cepstral Coefficients)**: Capturam as caracter√≠sticas espectrais do √°udio.
- **Chroma Features**: Representam as energias das notas musicais.
- **Spectral Contrast**: Diferen√ßa entre os picos e vales no espectro de frequ√™ncias.
- **Zero-Crossing Rate**: Taxa de mudan√ßa de sinal no √°udio.

As features foram extra√≠das usando a biblioteca **librosa** e normalizadas para melhor desempenho do modelo.

### 3. Treinamento do Modelo

- **Modelo Utilizado**:
  - Um modelo de aprendizado de m√°quina foi treinado para classificar as emo√ß√µes com base nas features extra√≠das.
  - Frameworks como **TensorFlow/Keras** foram utilizados.

- **Divis√£o dos Dados**:
  - O dataset foi dividido em conjuntos de treinamento, valida√ß√£o e teste.
  - Foi utilizada valida√ß√£o cruzada para evitar overfitting e avaliar a performance do modelo.

### 4. Interface com Streamlit

- **Funcionalidades**:
  - Upload de arquivos de √°udio pelo usu√°rio.
  - Predi√ß√£o da emo√ß√£o baseada no modelo treinado.
  - Exibi√ß√£o de resultados com a probabilidade de cada emo√ß√£o.

### 5. Avalia√ß√£o do Modelo

- **M√©tricas de Avalia√ß√£o**:
  - Acur√°cia
  - Matriz de confus√£o
  - F1-score, precis√£o e recall

- **Resultados**:
  - O desempenho do modelo foi avaliado nos dados de teste, e os resultados foram apresentados em forma de relat√≥rios e gr√°ficos no Streamlit.

---

## Como Executar o Projeto

1. Clone este reposit√≥rio:
   ```bash
   git clone https://github.com/seu-usuario/audio-emotion-classification.git
   ```

2. Instale as depend√™ncias:
   ```bash
   pip install -r requirements.txt
   ```

3. Baixe o dataset RAVDESS e organize os arquivos conforme descrito no c√≥digo.

4. Execute o aplicativo Streamlit:
   ```bash
   streamlit run app.py
   ```

5. Envie um arquivo de √°udio no aplicativo e veja o modelo predizer a emo√ß√£o presente.

---

## Tecnologias Utilizadas

- **Python**
- **Streamlit**
- **Librosa**
- **TensorFlow/Keras**
- **Matplotlib/Seaborn** (para visualiza√ß√µes)

---

## Pr√≥ximos Passos

- Adicionar suporte para outros datasets e emo√ß√µes.
- Melhorar a interface do Streamlit com gr√°ficos interativos.
- Implementar detec√ß√£o em tempo real para grava√ß√µes ao vivo.

---

## Conclus√£o
Podemos ver que nosso modelo √© mais preciso na predi√ß√£o das emo√ß√µes surpresa e raiva, o que faz sentido, pois os arquivos de √°udio dessas emo√ß√µes diferem bastante dos outros em aspectos como tom, velocidade, etc. Caso voc√™ queira contribuir sinta-se a vontade e me contate em: schmittluigi@gmail.com ou se voc√™ me conhece fale comigo :)

---

